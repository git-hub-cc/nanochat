[project]
name = "nanochat"
version = "0.1.0"
description = "the minimal full-stack ChatGPT clone"
readme = "README.md"
requires-python = ">=3.10"
dependencies = [
    "datasets>=4.0.0",
    "fastapi>=0.117.1",
    "files-to-prompt>=0.6",
    "pandas>=2.0.0",
    "psutil>=7.1.0",
    "pyarrow>=15.0.0",
    "regex>=2025.9.1",
    "setuptools>=80.9.0",
    "tiktoken>=0.11.0",
    "tokenizers>=0.22.0",
    # --- 修改点：修正 torch 版本并添加 DirectML ---
    "torch>=2.0.0",
    "torch-directml",
    # -------------------------------------------
    "uvicorn>=0.36.0",
    "wandb>=0.21.3"
]

[build-system]
requires = ["maturin>=1.7,<2.0"]
build-backend = "maturin"

[tool.maturin]
module-name = "rustbpe"
bindings = "pyo3"
python-source = "."
manifest-path = "rustbpe/Cargo.toml"

[dependency-groups]
dev = [
    "maturin>=1.9.4",
    "pytest>=8.0.0",
]

[tool.pytest.ini_options]
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
]
testpaths = ["tests"]
python_files = ["test_*.py"]
python_classes = ["Test*"]
python_functions = ["test_*"]

# --- 可选优化：强制下载 CPU 版本的 Torch ---
# DirectML 不需要 Nvidia CUDA 版本的 Torch，使用 CPU 版本可以节省约 2GB 空间。
# 如果下载太慢或体积太大，可以取消注释以下两段配置：

# [tool.uv.sources]
# torch = [
#   { index = "pytorch-cpu" },
# ]
#
# [[tool.uv.index]]
# name = "pytorch-cpu"
# url = "https://download.pytorch.org/whl/cpu"
# explicit = true

[project.optional-dependencies]
cpu = [
    "torch>=2.0.0",
]
gpu = [
    "torch>=2.0.0",
]